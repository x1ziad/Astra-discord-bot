"""
üöÄ ULTRA-PERFORMANCE SYSTEM COORDINATOR
Synchronizes all system components for maximum performance and coherence

This module provides:
- Centralized system coordination
- Performance optimization across all components
- Cohesive integration between all cogs
- Real-time monitoring and adaptive optimization
- Memory management and caching strategies
- Telemetry and performance analytics

Author: x1ziad
Version: 2.0.0 PERFORMANCE
"""

import asyncio
import logging
import time
import gc
from typing import Dict, List, Optional, Any, Set, Callable
from datetime import datetime, timezone, timedelta
from dataclasses import dataclass, field
from enum import Enum
import weakref
from pathlib import Path
import psutil
import sys

# Performance imports with fallbacks
try:
    import orjson as fast_json

    USE_FAST_JSON = True
except ImportError:
    import json as fast_json

    USE_FAST_JSON = False

try:
    import uvloop

    USE_UVLOOP = True
except ImportError:
    USE_UVLOOP = False

import discord
from discord.ext import commands

logger = logging.getLogger("astra.system_coordinator")


class SystemPriority(Enum):
    """System component priorities"""

    CRITICAL = 0  # Security, error handling
    HIGH = 1  # AI responses, user interactions
    NORMAL = 2  # Regular commands, features
    LOW = 3  # Analytics, background tasks
    BACKGROUND = 4  # Cleanup, maintenance


class ComponentStatus(Enum):
    """Component status states"""

    INITIALIZING = "initializing"
    ACTIVE = "active"
    DEGRADED = "degraded"
    ERROR = "error"
    DISABLED = "disabled"


@dataclass
class ComponentMetrics:
    """Performance metrics for system components"""

    name: str
    status: ComponentStatus = ComponentStatus.INITIALIZING
    requests_processed: int = 0
    avg_response_time: float = 0.0
    error_count: int = 0
    last_error: Optional[str] = None
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    health_score: float = 100.0


@dataclass
class SystemMetrics:
    """Overall system performance metrics"""

    total_requests: int = 0
    total_errors: int = 0
    avg_response_time: float = 0.0
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    cache_hit_rate: float = 0.0
    concurrent_operations: int = 0
    uptime_seconds: float = 0.0
    components_healthy: int = 0
    components_total: int = 0


class UltraPerformanceCoordinator:
    """
    üöÄ ULTRA-PERFORMANCE SYSTEM COORDINATOR

    Manages and optimizes all system components for maximum performance:
    - Centralized request routing and load balancing
    - Dynamic performance optimization
    - Memory management and garbage collection
    - Component health monitoring
    - Adaptive resource allocation
    - Real-time performance analytics
    """

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.logger = logging.getLogger("astra.system_coordinator")

        # System state
        self.start_time = time.time()
        self.initialized = False
        self.shutdown_initiated = False

        # Component tracking
        self.components: Dict[str, ComponentMetrics] = {}
        self.component_instances: Dict[str, Any] = {}
        self.component_tasks: Dict[str, Set[asyncio.Task]] = {}

        # Performance optimization
        self.request_queue: Dict[SystemPriority, asyncio.Queue] = {
            priority: asyncio.Queue(maxsize=1000) for priority in SystemPriority
        }
        self.active_workers: Dict[SystemPriority, int] = {
            priority: 0 for priority in SystemPriority
        }
        self.max_workers: Dict[SystemPriority, int] = {
            SystemPriority.CRITICAL: 10,
            SystemPriority.HIGH: 8,
            SystemPriority.NORMAL: 6,
            SystemPriority.LOW: 4,
            SystemPriority.BACKGROUND: 2,
        }

        # System metrics
        self.metrics = SystemMetrics()
        self.performance_history: List[Dict[str, Any]] = []

        # Caching system
        self.global_cache: Dict[str, Any] = {}
        self.cache_ttl: Dict[str, datetime] = {}
        self.cache_stats = {"hits": 0, "misses": 0}

        # Resource management
        self.memory_threshold_mb = 800  # Alert threshold
        self.cpu_threshold_percent = 80  # Alert threshold
        self.gc_frequency = 300  # 5 minutes
        self.last_gc_time = time.time()

        # Event system for component communication
        self.event_handlers: Dict[str, List[Callable]] = {}

        self.logger.info("üöÄ Ultra-Performance System Coordinator initialized")

    async def initialize(self):
        """Initialize the system coordinator and all components"""
        try:
            self.logger.info("üîß Initializing Ultra-Performance System Coordinator...")

            # Start worker pools
            await self._start_worker_pools()

            # Initialize component monitoring
            await self._initialize_component_monitoring()

            # Start background optimization tasks
            self._start_background_tasks()

            # Register core components
            await self._register_core_components()

            # Initialize performance monitoring
            await self._initialize_performance_monitoring()

            self.initialized = True
            self.logger.info("‚úÖ Ultra-Performance System Coordinator ready")

        except Exception as e:
            self.logger.error(f"‚ùå System Coordinator initialization failed: {e}")
            raise

    async def _start_worker_pools(self):
        """Start optimized worker pools for different priority levels"""
        for priority in SystemPriority:
            for _ in range(self.max_workers[priority]):
                worker_task = asyncio.create_task(
                    self._priority_worker(priority),
                    name=f"worker_{priority.name.lower()}_{_}",
                )

                if priority not in self.component_tasks:
                    self.component_tasks[priority.name] = set()
                self.component_tasks[priority.name].add(worker_task)

        self.logger.info(
            f"‚ö° Started {sum(self.max_workers.values())} optimized workers"
        )

    async def _priority_worker(self, priority: SystemPriority):
        """Worker for processing requests by priority"""
        queue = self.request_queue[priority]

        while not self.shutdown_initiated:
            try:
                # Get request from queue with timeout
                request = await asyncio.wait_for(queue.get(), timeout=1.0)

                self.active_workers[priority] += 1
                start_time = time.time()

                try:
                    # Process the request
                    await self._process_request(request, priority)

                    # Update metrics
                    processing_time = time.time() - start_time
                    self._update_performance_metrics(processing_time, success=True)

                except Exception as e:
                    processing_time = time.time() - start_time
                    self._update_performance_metrics(processing_time, success=False)
                    self.logger.error(f"Request processing error: {e}")

                finally:
                    self.active_workers[priority] -= 1
                    queue.task_done()

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                self.logger.error(f"Worker error ({priority.name}): {e}")
                await asyncio.sleep(1)

    async def _process_request(self, request: Dict[str, Any], priority: SystemPriority):
        """Process a system request"""
        request_type = request.get("type")
        component = request.get("component")
        data = request.get("data", {})
        callback = request.get("callback")

        try:
            # Route to appropriate component
            if component in self.component_instances:
                component_instance = self.component_instances[component]

                # Call component method if specified
                if "method" in request:
                    method = getattr(component_instance, request["method"], None)
                    if method:
                        result = (
                            await method(**data)
                            if asyncio.iscoroutinefunction(method)
                            else method(**data)
                        )

                        if callback:
                            await callback(result)

                # Update component metrics
                self._update_component_metrics(component, success=True)

        except Exception as e:
            if component:
                self._update_component_metrics(component, success=False, error=str(e))
            raise

    async def _register_core_components(self):
        """Register and initialize core system components"""
        core_components = [
            "SecurityManager",
            "AICompanion",
            "HighPerformanceCoordinator",
            "Analytics",
            "PersonalityManager",
            "BotSetupEnhanced",
            "Nexus",
            "AdminOptimized",
        ]

        for component_name in core_components:
            try:
                component = self.bot.get_cog(component_name)
                if component:
                    await self.register_component(component_name, component)
                    self.logger.info(f"‚úÖ Registered {component_name}")
                else:
                    self.logger.warning(f"‚ö†Ô∏è Component {component_name} not found")

            except Exception as e:
                self.logger.error(f"‚ùå Failed to register {component_name}: {e}")

    async def register_component(
        self, name: str, instance: Any, priority: SystemPriority = SystemPriority.NORMAL
    ):
        """Register a system component for monitoring and coordination"""
        try:
            # Create component metrics
            metrics = ComponentMetrics(name=name, status=ComponentStatus.ACTIVE)

            self.components[name] = metrics
            self.component_instances[name] = instance
            self.metrics.components_total += 1
            self.metrics.components_healthy += 1

            # Initialize component tasks tracking
            if name not in self.component_tasks:
                self.component_tasks[name] = set()

            self.logger.info(f"üì¶ Registered component: {name}")

        except Exception as e:
            self.logger.error(f"Failed to register component {name}: {e}")

    async def queue_request(
        self,
        component: str,
        request_type: str,
        data: Dict[str, Any] = None,
        priority: SystemPriority = SystemPriority.NORMAL,
        callback: Optional[Callable] = None,
    ) -> bool:
        """Queue a request for processing"""
        try:
            request = {
                "type": request_type,
                "component": component,
                "data": data or {},
                "callback": callback,
                "timestamp": time.time(),
            }

            queue = self.request_queue[priority]

            # Check if queue is full
            if queue.full():
                self.logger.warning(f"Queue full for {priority.name}, dropping request")
                return False

            await queue.put(request)
            self.metrics.total_requests += 1

            return True

        except Exception as e:
            self.logger.error(f"Failed to queue request: {e}")
            return False

    def _update_component_metrics(
        self, component: str, success: bool = True, error: str = None
    ):
        """Update metrics for a component"""
        if component not in self.components:
            return

        metrics = self.components[component]
        metrics.requests_processed += 1
        metrics.last_updated = datetime.now(timezone.utc)

        if not success:
            metrics.error_count += 1
            metrics.last_error = error
            metrics.status = ComponentStatus.DEGRADED
            metrics.health_score = max(0, metrics.health_score - 5)
        else:
            # Gradual health recovery
            metrics.health_score = min(100, metrics.health_score + 1)
            if metrics.health_score > 90:
                metrics.status = ComponentStatus.ACTIVE

    def _update_performance_metrics(self, processing_time: float, success: bool = True):
        """Update system-wide performance metrics"""
        # Update response time (moving average)
        if self.metrics.total_requests > 0:
            self.metrics.avg_response_time = (
                self.metrics.avg_response_time * self.metrics.total_requests
                + processing_time
            ) / (self.metrics.total_requests + 1)
        else:
            self.metrics.avg_response_time = processing_time

        if not success:
            self.metrics.total_errors += 1

    async def _initialize_component_monitoring(self):
        """Initialize advanced component monitoring"""
        # Start component health check task
        asyncio.create_task(self._component_health_monitor())

        # Start resource monitoring
        asyncio.create_task(self._resource_monitor())

        self.logger.info("üîç Component monitoring initialized")

    async def _component_health_monitor(self):
        """Monitor component health and automatically recover failed components"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(30)  # Check every 30 seconds

                unhealthy_components = []

                for name, metrics in self.components.items():
                    # Check if component is unresponsive
                    time_since_update = (
                        datetime.now(timezone.utc) - metrics.last_updated
                    ).total_seconds()

                    if time_since_update > 300:  # 5 minutes
                        metrics.status = ComponentStatus.ERROR
                        metrics.health_score = max(0, metrics.health_score - 10)
                        unhealthy_components.append(name)

                    # Check error rate
                    if metrics.requests_processed > 0:
                        error_rate = metrics.error_count / metrics.requests_processed
                        if error_rate > 0.1:  # >10% error rate
                            metrics.status = ComponentStatus.DEGRADED
                            unhealthy_components.append(name)

                # Attempt recovery for unhealthy components
                for component_name in unhealthy_components:
                    await self._attempt_component_recovery(component_name)

                # Update system health metrics
                healthy_count = sum(
                    1
                    for m in self.components.values()
                    if m.status == ComponentStatus.ACTIVE
                )
                self.metrics.components_healthy = healthy_count

            except Exception as e:
                self.logger.error(f"Component health monitor error: {e}")

    async def _attempt_component_recovery(self, component_name: str):
        """Attempt to recover a failed component"""
        try:
            self.logger.warning(f"üîß Attempting recovery for {component_name}")

            component = self.component_instances.get(component_name)
            if not component:
                return

            # Try to reinitialize component if it has an initialize method
            if hasattr(component, "initialize"):
                await component.initialize()

            # Reset metrics
            metrics = self.components[component_name]
            metrics.status = ComponentStatus.ACTIVE
            metrics.health_score = 75  # Partial recovery
            metrics.error_count = 0
            metrics.last_error = None

            self.logger.info(f"‚úÖ Recovery successful for {component_name}")

        except Exception as e:
            self.logger.error(f"‚ùå Recovery failed for {component_name}: {e}")
            self.components[component_name].status = ComponentStatus.ERROR

    async def _resource_monitor(self):
        """Monitor system resources and optimize performance"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(60)  # Check every minute

                # Get system metrics
                process = psutil.Process()
                memory_mb = process.memory_info().rss / 1024 / 1024
                cpu_percent = process.cpu_percent()

                self.metrics.memory_usage_mb = memory_mb
                self.metrics.cpu_usage_percent = cpu_percent
                self.metrics.uptime_seconds = time.time() - self.start_time

                # Check thresholds
                if memory_mb > self.memory_threshold_mb:
                    self.logger.warning(f"üö® High memory usage: {memory_mb:.1f}MB")
                    await self._optimize_memory_usage()

                if cpu_percent > self.cpu_threshold_percent:
                    self.logger.warning(f"üö® High CPU usage: {cpu_percent:.1f}%")
                    await self._optimize_cpu_usage()

                # Periodic garbage collection
                current_time = time.time()
                if current_time - self.last_gc_time > self.gc_frequency:
                    collected = gc.collect()
                    self.last_gc_time = current_time
                    if collected > 0:
                        self.logger.info(
                            f"üßπ Garbage collection: {collected} objects freed"
                        )

                # Update cache hit rate
                total_cache_ops = self.cache_stats["hits"] + self.cache_stats["misses"]
                if total_cache_ops > 0:
                    self.metrics.cache_hit_rate = (
                        self.cache_stats["hits"] / total_cache_ops
                    ) * 100

                # Record performance history
                self.performance_history.append(
                    {
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "memory_mb": memory_mb,
                        "cpu_percent": cpu_percent,
                        "requests_total": self.metrics.total_requests,
                        "errors_total": self.metrics.total_errors,
                        "avg_response_time": self.metrics.avg_response_time,
                        "components_healthy": self.metrics.components_healthy,
                    }
                )

                # Keep only recent history
                if len(self.performance_history) > 1440:  # 24 hours of minutes
                    self.performance_history = self.performance_history[-1440:]

            except Exception as e:
                self.logger.error(f"Resource monitor error: {e}")

    async def _optimize_memory_usage(self):
        """Optimize memory usage when threshold is exceeded"""
        try:
            # Clear expired cache entries
            now = datetime.now(timezone.utc)
            expired_keys = [
                key for key, expiry in self.cache_ttl.items() if now > expiry
            ]

            for key in expired_keys:
                self.global_cache.pop(key, None)
                self.cache_ttl.pop(key, None)

            # Limit cache size
            if len(self.global_cache) > 1000:
                # Remove oldest entries
                sorted_cache = sorted(self.cache_ttl.items(), key=lambda x: x[1])
                to_remove = sorted_cache[: len(sorted_cache) // 2]

                for key, _ in to_remove:
                    self.global_cache.pop(key, None)
                    self.cache_ttl.pop(key, None)

            # Force garbage collection
            collected = gc.collect()

            self.logger.info(
                f"üßπ Memory optimization: {len(expired_keys)} cache entries cleared, {collected} objects freed"
            )

        except Exception as e:
            self.logger.error(f"Memory optimization error: {e}")

    async def _optimize_cpu_usage(self):
        """Optimize CPU usage when threshold is exceeded"""
        try:
            # Reduce worker counts temporarily
            for priority in [SystemPriority.LOW, SystemPriority.BACKGROUND]:
                if self.active_workers[priority] > 1:
                    # This would require more complex worker management
                    # For now, just log the optimization attempt
                    pass

            # Add small delays to high-frequency operations
            await asyncio.sleep(0.1)

            self.logger.info("üîß CPU optimization applied")

        except Exception as e:
            self.logger.error(f"CPU optimization error: {e}")

    def _start_background_tasks(self):
        """Start optimized background maintenance tasks"""
        # Performance analytics task
        asyncio.create_task(self._performance_analytics_task())

        # Cache cleanup task
        asyncio.create_task(self._cache_cleanup_task())

        # System optimization task
        asyncio.create_task(self._system_optimization_task())

        self.logger.info("üîÑ Background optimization tasks started")

    async def _performance_analytics_task(self):
        """Advanced performance analytics and optimization"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(600)  # Every 10 minutes

                # Analyze performance trends
                if len(self.performance_history) > 10:
                    recent_metrics = self.performance_history[-10:]

                    # Calculate trends
                    memory_trend = self._calculate_trend(
                        [m["memory_mb"] for m in recent_metrics]
                    )
                    cpu_trend = self._calculate_trend(
                        [m["cpu_percent"] for m in recent_metrics]
                    )
                    response_time_trend = self._calculate_trend(
                        [m["avg_response_time"] for m in recent_metrics]
                    )

                    # Log analytics
                    self.logger.info("üìä PERFORMANCE ANALYTICS:")
                    self.logger.info(
                        f"   üìà Memory Trend: {'‚ÜóÔ∏è' if memory_trend > 0.1 else '‚ÜòÔ∏è' if memory_trend < -0.1 else '‚û°Ô∏è'}"
                    )
                    self.logger.info(
                        f"   üìà CPU Trend: {'‚ÜóÔ∏è' if cpu_trend > 0.1 else '‚ÜòÔ∏è' if cpu_trend < -0.1 else '‚û°Ô∏è'}"
                    )
                    self.logger.info(
                        f"   üìà Response Time Trend: {'‚ÜóÔ∏è' if response_time_trend > 0.1 else '‚ÜòÔ∏è' if response_time_trend < -0.1 else '‚û°Ô∏è'}"
                    )

                    # Predict and prevent performance issues
                    if memory_trend > 0.2:  # Memory increasing rapidly
                        self.logger.warning(
                            "üö® Memory usage trending up - triggering optimization"
                        )
                        await self._optimize_memory_usage()

                    if response_time_trend > 0.2:  # Response times increasing
                        self.logger.warning(
                            "üö® Response times trending up - optimizing request handling"
                        )
                        # Could implement request throttling here

            except Exception as e:
                self.logger.error(f"Performance analytics error: {e}")

    def _calculate_trend(self, values: List[float]) -> float:
        """Calculate trend direction (-1 to 1) for a series of values"""
        if len(values) < 2:
            return 0.0

        # Simple linear regression slope
        n = len(values)
        x_mean = (n - 1) / 2
        y_mean = sum(values) / n

        numerator = sum((i - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((i - x_mean) ** 2 for i in range(n))

        if denominator == 0:
            return 0.0

        slope = numerator / denominator

        # Normalize to -1 to 1 range
        return max(-1, min(1, slope / max(values) if max(values) > 0 else 0))

    async def _cache_cleanup_task(self):
        """Optimized cache cleanup task"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(300)  # Every 5 minutes

                now = datetime.now(timezone.utc)
                expired_count = 0

                # Clean expired entries
                expired_keys = [
                    key for key, expiry in self.cache_ttl.items() if now > expiry
                ]

                for key in expired_keys:
                    self.global_cache.pop(key, None)
                    self.cache_ttl.pop(key, None)
                    expired_count += 1

                if expired_count > 0:
                    self.logger.debug(
                        f"üßπ Cache cleanup: {expired_count} expired entries removed"
                    )

            except Exception as e:
                self.logger.error(f"Cache cleanup error: {e}")

    async def _system_optimization_task(self):
        """Continuous system optimization"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(900)  # Every 15 minutes

                # Optimize worker allocation based on queue sizes
                for priority in SystemPriority:
                    queue = self.request_queue[priority]
                    queue_size = queue.qsize()
                    active = self.active_workers[priority]
                    max_workers = self.max_workers[priority]

                    # Dynamic worker scaling (simplified)
                    if queue_size > max_workers * 2 and active < max_workers:
                        self.logger.info(
                            f"üîß High queue size for {priority.name}, consider scaling"
                        )
                    elif queue_size == 0 and active > 1:
                        self.logger.debug(
                            f"üîß Low queue size for {priority.name}, could scale down"
                        )

                # Log optimization summary
                self.logger.info("üîß System optimization cycle completed")

            except Exception as e:
                self.logger.error(f"System optimization error: {e}")

    async def _initialize_performance_monitoring(self):
        """Initialize comprehensive performance monitoring"""
        # Start performance monitoring
        asyncio.create_task(self._performance_monitor_task())

        self.logger.info("üìä Performance monitoring initialized")

    async def _performance_monitor_task(self):
        """üöÄ ULTIMATE performance monitoring task with real-time optimization"""
        while not self.shutdown_initiated:
            try:
                await asyncio.sleep(60)  # üöÄ More frequent monitoring - every minute

                # Calculate concurrent operations
                self.metrics.concurrent_operations = sum(self.active_workers.values())

                # üöÄ Real-time performance optimization
                await self._real_time_optimization()

                # üöÄ Predictive performance analysis
                await self._predictive_analysis()

                # Log comprehensive metrics more frequently for better insights
                if (
                    self.metrics.total_requests % 500 == 0  # üöÄ More frequent logging
                    and self.metrics.total_requests > 0
                ):
                    await self._log_enhanced_performance_summary()

            except Exception as e:
                self.logger.error(f"Performance monitor error: {e}")

    async def _real_time_optimization(self):
        """ÔøΩ Real-time performance optimization"""
        try:
            current_time = time.time()
            
            # üöÄ Dynamic cache optimization
            if self.metrics.cache_hit_rate < 70:
                await self._optimize_cache_strategy()
            
            # üöÄ Memory pressure detection and relief
            if self.metrics.memory_usage_mb > 400:  # 400MB threshold
                await self._emergency_memory_optimization()
            
            # üöÄ Response time optimization
            if self.metrics.avg_response_time > 1.5:  # 1.5s threshold
                await self._optimize_response_times()
            
            # üöÄ Queue management optimization
            await self._optimize_queue_management()
            
        except Exception as e:
            self.logger.error(f"Real-time optimization error: {e}")

    async def _optimize_cache_strategy(self):
        """üöÄ Optimize caching strategy dynamically"""
        try:
            # Analyze cache patterns
            total_ops = self.cache_stats["hits"] + self.cache_stats["misses"]
            if total_ops > 100:
                hit_rate = (self.cache_stats["hits"] / total_ops) * 100
                
                if hit_rate < 50:  # Poor hit rate
                    # Increase cache TTL for better retention
                    self.default_cache_ttl = min(self.default_cache_ttl * 1.2, 1800)  # Max 30 minutes
                    self.logger.info(f"üîÑ Increased cache TTL to {self.default_cache_ttl}s for better hit rate")
                elif hit_rate > 90:  # Excellent hit rate
                    # Can afford to reduce cache size slightly
                    if len(self.global_cache) > 2000:
                        # Remove 10% of oldest entries
                        sorted_cache = sorted(self.cache_ttl.items(), key=lambda x: x[1])
                        to_remove = sorted_cache[:len(sorted_cache) // 10]
                        for key, _ in to_remove:
                            self.global_cache.pop(key, None)
                            self.cache_ttl.pop(key, None)
                        self.logger.info("üßπ Optimized cache size while maintaining high hit rate")
                        
        except Exception as e:
            self.logger.error(f"Cache strategy optimization error: {e}")

    async def _emergency_memory_optimization(self):
        """üöÄ Emergency memory optimization"""
        try:
            self.logger.warning("üö® High memory usage detected - applying emergency optimizations")
            
            # 1. Aggressive cache cleanup
            cache_size_before = len(self.global_cache)
            
            # Keep only 50% of cache, prioritizing most recent
            if cache_size_before > 500:
                sorted_cache = sorted(self.cache_ttl.items(), key=lambda x: x[1], reverse=True)
                keep_count = cache_size_before // 2
                
                # Clear old entries
                for key, _ in sorted_cache[keep_count:]:
                    self.global_cache.pop(key, None)
                    self.cache_ttl.pop(key, None)
            
            # 2. Force multiple garbage collection rounds
            total_collected = 0
            for _ in range(3):
                collected = gc.collect()
                total_collected += collected
                if collected == 0:
                    break
                await asyncio.sleep(0.1)  # Brief pause between GC rounds
            
            cache_size_after = len(self.global_cache)
            self.logger.info(
                f"üßπ Emergency cleanup: Cache {cache_size_before}‚Üí{cache_size_after}, "
                f"GC collected {total_collected} objects"
            )
            
        except Exception as e:
            self.logger.error(f"Emergency memory optimization error: {e}")

    async def _optimize_response_times(self):
        """üöÄ Optimize response times"""
        try:
            self.logger.warning("‚ö° High response times detected - optimizing")
            
            # Temporarily reduce queue processing delays
            for priority in SystemPriority:
                if self.active_workers[priority] < self.max_workers[priority]:
                    # Could increase workers here if needed
                    pass
            
            # Clear any potential bottlenecks
            await asyncio.sleep(0.05)  # Brief pause to let queues catch up
            
        except Exception as e:
            self.logger.error(f"Response time optimization error: {e}")

    async def _optimize_queue_management(self):
        """üöÄ Optimize queue management"""
        try:
            total_queued = sum(queue.qsize() for queue in self.request_queue.values())
            
            if total_queued > 100:  # High queue pressure
                # Prioritize critical operations
                critical_queue = self.request_queue[SystemPriority.CRITICAL]
                high_queue = self.request_queue[SystemPriority.HIGH]
                
                # Log queue status for monitoring
                self.logger.info(f"üîÑ Queue pressure: {total_queued} total items queued")
                
        except Exception as e:
            self.logger.error(f"Queue optimization error: {e}")

    async def _predictive_analysis(self):
        """ÔøΩ Predictive performance analysis"""
        try:
            if len(self.performance_history) >= 5:
                recent_metrics = self.performance_history[-5:]
                
                # Predict memory trend
                memory_values = [m["memory_mb"] for m in recent_metrics]
                memory_trend = self._calculate_trend(memory_values)
                
                # Predict response time trend
                response_times = [m["avg_response_time"] for m in recent_metrics]
                response_trend = self._calculate_trend(response_times)
                
                # Proactive optimizations based on predictions
                if memory_trend > 0.3:  # Memory rapidly increasing
                    self.logger.info("üîÆ Predicted memory pressure - applying proactive optimization")
                    await self._proactive_memory_cleanup()
                
                if response_trend > 0.3:  # Response times increasing
                    self.logger.info("üîÆ Predicted response time degradation - optimizing")
                    await self._proactive_response_optimization()
                    
        except Exception as e:
            self.logger.error(f"Predictive analysis error: {e}")

    async def _proactive_memory_cleanup(self):
        """ÔøΩ Proactive memory cleanup"""
        try:
            # Light cleanup before memory becomes critical
            cache_size = len(self.global_cache)
            if cache_size > 1000:
                # Remove 20% of oldest entries
                sorted_cache = sorted(self.cache_ttl.items(), key=lambda x: x[1])
                to_remove = sorted_cache[:cache_size // 5]
                
                for key, _ in to_remove:
                    self.global_cache.pop(key, None)
                    self.cache_ttl.pop(key, None)
                
                self.logger.info(f"üßπ Proactive cache cleanup: removed {len(to_remove)} entries")
            
            # Light garbage collection
            collected = gc.collect()
            if collected > 0:
                self.logger.info(f"üßπ Proactive GC: {collected} objects collected")
                
        except Exception as e:
            self.logger.error(f"Proactive memory cleanup error: {e}")

    async def _proactive_response_optimization(self):
        """ÔøΩ Proactive response time optimization"""
        try:
            # Reduce processing delays
            # This could involve adjusting worker sleep times, queue priorities, etc.
            self.logger.info("‚ö° Applied proactive response time optimizations")
            
        except Exception as e:
            self.logger.error(f"Proactive response optimization error: {e}")

    async def _log_enhanced_performance_summary(self):
        """üöÄ Enhanced performance summary logging"""
        try:
            # Calculate additional metrics
            uptime_hours = (time.time() - self.start_time) / 3600
            requests_per_hour = self.metrics.total_requests / uptime_hours if uptime_hours > 0 else 0
            error_rate = (self.metrics.total_errors / self.metrics.total_requests * 100) if self.metrics.total_requests > 0 else 0
            
            self.logger.info("üöÄ ULTIMATE PERFORMANCE SUMMARY:")
            self.logger.info(f"   üìà Total Requests: {self.metrics.total_requests:,} ({requests_per_hour:.1f}/hr)")
            self.logger.info(f"   ‚ö° Avg Response Time: {self.metrics.avg_response_time*1000:.1f}ms")
            self.logger.info(f"   üéØ Cache Hit Rate: {self.metrics.cache_hit_rate:.1f}%")
            self.logger.info(f"   üíæ Memory Usage: {self.metrics.memory_usage_mb:.1f}MB")
            self.logger.info(f"   üñ•Ô∏è  CPU Usage: {self.metrics.cpu_usage_percent:.1f}%")
            self.logger.info(f"   ‚ùå Error Rate: {error_rate:.2f}%")
            self.logger.info(f"   üîß Components Healthy: {self.metrics.components_healthy}/{self.metrics.components_total}")
            self.logger.info(f"   üîÑ Concurrent Ops: {self.metrics.concurrent_operations}")
            self.logger.info(f"   ‚è±Ô∏è Uptime: {uptime_hours:.2f}h")
            
        except Exception as e:
            self.logger.error(f"Enhanced performance logging error: {e}")

    # Public API methods

    def get_cache(self, key: str) -> Any:
        """Get value from global cache"""
        if key in self.global_cache:
            # Check if expired
            if (
                key in self.cache_ttl
                and datetime.now(timezone.utc) > self.cache_ttl[key]
            ):
                self.global_cache.pop(key, None)
                self.cache_ttl.pop(key, None)
                self.cache_stats["misses"] += 1
                return None

            self.cache_stats["hits"] += 1
            return self.global_cache[key]

        self.cache_stats["misses"] += 1
        return None

    def set_cache(self, key: str, value: Any, ttl_seconds: int = 300):
        """Set value in global cache with TTL"""
        self.global_cache[key] = value
        self.cache_ttl[key] = datetime.now(timezone.utc) + timedelta(
            seconds=ttl_seconds
        )

    def emit_event(self, event_name: str, data: Dict[str, Any] = None):
        """Emit system event to registered handlers"""
        if event_name in self.event_handlers:
            for handler in self.event_handlers[event_name]:
                try:
                    asyncio.create_task(handler(data or {}))
                except Exception as e:
                    self.logger.error(f"Event handler error: {e}")

    def register_event_handler(self, event_name: str, handler: Callable):
        """Register event handler"""
        if event_name not in self.event_handlers:
            self.event_handlers[event_name] = []
        self.event_handlers[event_name].append(handler)

    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        return {
            "initialized": self.initialized,
            "uptime_seconds": time.time() - self.start_time,
            "metrics": {
                "total_requests": self.metrics.total_requests,
                "total_errors": self.metrics.total_errors,
                "avg_response_time_ms": self.metrics.avg_response_time * 1000,
                "memory_usage_mb": self.metrics.memory_usage_mb,
                "cpu_usage_percent": self.metrics.cpu_usage_percent,
                "cache_hit_rate": self.metrics.cache_hit_rate,
                "concurrent_operations": self.metrics.concurrent_operations,
                "components_healthy": self.metrics.components_healthy,
                "components_total": self.metrics.components_total,
            },
            "components": {
                name: {
                    "status": metrics.status.value,
                    "requests_processed": metrics.requests_processed,
                    "error_count": metrics.error_count,
                    "health_score": metrics.health_score,
                    "avg_response_time": metrics.avg_response_time,
                }
                for name, metrics in self.components.items()
            },
            "queues": {
                priority.name: {
                    "size": self.request_queue[priority].qsize(),
                    "active_workers": self.active_workers[priority],
                    "max_workers": self.max_workers[priority],
                }
                for priority in SystemPriority
            },
        }

    async def shutdown(self):
        """Graceful shutdown of the system coordinator"""
        self.logger.info("üîÑ Initiating system coordinator shutdown...")

        self.shutdown_initiated = True

        try:
            # Wait for queues to empty
            for priority, queue in self.request_queue.items():
                if not queue.empty():
                    self.logger.info(
                        f"‚è≥ Waiting for {priority.name} queue to empty..."
                    )
                    await queue.join()

            # Cancel all component tasks
            for component_name, tasks in self.component_tasks.items():
                for task in tasks:
                    if not task.done():
                        task.cancel()

                # Wait for tasks to complete
                if tasks:
                    await asyncio.gather(*tasks, return_exceptions=True)

            # Final metrics log
            self.logger.info("üìä FINAL SYSTEM METRICS:")
            self.logger.info(f"   üìà Total Requests: {self.metrics.total_requests:,}")
            self.logger.info(f"   ‚ùå Total Errors: {self.metrics.total_errors:,}")
            self.logger.info(
                f"   ‚è±Ô∏è Uptime: {(time.time() - self.start_time)/3600:.2f}h"
            )
            self.logger.info(
                f"   üéØ Cache Hit Rate: {self.metrics.cache_hit_rate:.1f}%"
            )

            self.logger.info("‚úÖ System coordinator shutdown completed")

        except Exception as e:
            self.logger.error(f"‚ùå Error during shutdown: {e}")


# Global instance
_system_coordinator: Optional[UltraPerformanceCoordinator] = None


async def get_system_coordinator(
    bot: commands.Bot = None,
) -> UltraPerformanceCoordinator:
    """Get or create the global system coordinator instance"""
    global _system_coordinator
    if _system_coordinator is None:
        if bot is None:
            raise ValueError("Bot instance required for first initialization")
        _system_coordinator = UltraPerformanceCoordinator(bot)
        await _system_coordinator.initialize()
    return _system_coordinator


async def initialize_system_coordinator(
    bot: commands.Bot,
) -> UltraPerformanceCoordinator:
    """Initialize the global system coordinator"""
    global _system_coordinator
    _system_coordinator = UltraPerformanceCoordinator(bot)
    await _system_coordinator.initialize()
    return _system_coordinator


# Compatibility aliases for testing
get_performance_coordinator = get_system_coordinator
initialize_performance_coordinator = initialize_system_coordinator
