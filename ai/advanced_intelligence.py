"""
Advanced Intelligence System for Astra Bot
Phase 3: Time-Aware Social Predictions, Cross-Server Intelligence, Wellness Companion,
Memory Palace, Mood Contagion, and Community Sage Mode

Features:
- Time-Aware Social Predictions: Next-level community management
- Cross-Server Intelligence: Learn from broader ecosystem
- Wellness Companion: Genuine care for community health
- Memory Palace: Advanced memory architecture
- Mood Contagion System: Emotional atmosphere tracking
- Community Sage Mode: Wise advisor with deep insights
"""

import asyncio
import logging
import json
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Set, Union
from datetime import datetime, timedelta, timezone
from collections import defaultdict, deque
from dataclasses import dataclass, field
from enum import Enum
import sqlite3
from pathlib import Path
import statistics
import math
from concurrent.futures import ThreadPoolExecutor
import threading

logger = logging.getLogger("astra.advanced_intelligence")


class SocialPredictionType(Enum):
    """Types of social predictions"""

    ACTIVITY_PEAK = "activity_peak"
    MOOD_SHIFT = "mood_shift"
    TOPIC_TREND = "topic_trend"
    CONFLICT_RISK = "conflict_risk"
    CELEBRATION_OPPORTUNITY = "celebration_opportunity"
    SUPPORT_NEED = "support_need"


class WellnessAlert(Enum):
    """Types of wellness alerts"""

    STRESS_DETECTED = "stress_detected"
    ISOLATION_RISK = "isolation_risk"
    BURNOUT_SIGNS = "burnout_signs"
    NEGATIVE_SPIRAL = "negative_spiral"
    SUPPORT_NEEDED = "support_needed"
    CELEBRATION_MISSED = "celebration_missed"


class MoodState(Enum):
    """Community mood states"""

    EUPHORIC = "euphoric"
    EXCITED = "excited"
    CONTENT = "content"
    NEUTRAL = "neutral"
    CONCERNED = "concerned"
    FRUSTRATED = "frustrated"
    DEJECTED = "dejected"


@dataclass
class SocialPrediction:
    """A prediction about community social patterns"""

    prediction_id: str
    server_id: int
    prediction_type: SocialPredictionType
    confidence: float  # 0.0 to 1.0
    predicted_time: datetime
    description: str
    contributing_factors: List[str]
    suggested_actions: List[str]
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    validated: Optional[bool] = None
    actual_outcome: Optional[str] = None


@dataclass
class WellnessProfile:
    """Individual user wellness profile"""

    user_id: int
    server_id: int

    # Stress indicators
    stress_level: float = 0.0  # 0.0 to 1.0
    message_sentiment_trend: List[float] = field(default_factory=list)
    activity_pattern_changes: List[Dict[str, Any]] = field(default_factory=list)

    # Social indicators
    isolation_risk: float = 0.0
    social_connection_strength: float = 0.5
    support_network_size: int = 0

    # Behavioral patterns
    typical_activity_hours: List[int] = field(default_factory=list)
    communication_frequency: float = 1.0  # Messages per day
    response_time_pattern: List[float] = field(default_factory=list)

    # Wellness history
    wellness_events: List[Dict[str, Any]] = field(default_factory=list)
    last_check_in: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    # Interventions
    recent_interventions: List[Dict[str, Any]] = field(default_factory=list)
    preferred_support_style: str = "gentle"  # gentle, direct, humorous


@dataclass
class MemoryFragment:
    """A fragment of community memory"""

    memory_id: str
    server_id: int
    memory_type: str  # event, relationship, achievement, tradition, etc.
    content: Dict[str, Any]
    emotional_weight: float  # -1.0 to 1.0
    importance_score: float  # 0.0 to 1.0
    participants: List[int]  # User IDs involved
    tags: List[str]
    created_at: datetime
    last_accessed: datetime
    access_count: int = 0
    connections: List[str] = field(default_factory=list)  # Connected memory IDs


@dataclass
class MoodSnapshot:
    """Snapshot of community mood at a point in time"""

    server_id: int
    timestamp: datetime
    overall_mood: MoodState
    mood_intensity: float  # 0.0 to 1.0
    dominant_emotions: Dict[str, float]  # emotion -> strength
    active_users: int
    message_sentiment_avg: float
    topics_discussed: List[str]
    mood_influencers: List[int]  # User IDs who influenced mood
    external_factors: List[str]  # Events, announcements, etc.


class TimeAwareSocialPredictor:
    """Predicts social patterns and optimal interaction times"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.prediction_history: Dict[int, List[SocialPrediction]] = defaultdict(list)
        self.activity_patterns: Dict[int, Dict[str, Any]] = {}
        self.social_graphs: Dict[int, Dict[str, Any]] = {}

    async def analyze_activity_patterns(
        self, server_id: int, historical_data: List[Dict]
    ) -> Dict[str, Any]:
        """Analyze historical activity patterns for predictions"""
        patterns = {
            "hourly_activity": defaultdict(list),
            "daily_activity": defaultdict(list),
            "topic_trends": defaultdict(list),
            "user_interaction_peaks": {},
            "seasonal_patterns": {},
        }

        for data_point in historical_data:
            timestamp = datetime.fromisoformat(data_point["timestamp"])
            hour = timestamp.hour
            day = timestamp.weekday()

            patterns["hourly_activity"][hour].append(data_point["activity_score"])
            patterns["daily_activity"][day].append(data_point["activity_score"])

            # Track topic trends
            for topic in data_point.get("topics", []):
                patterns["topic_trends"][topic].append(
                    {
                        "timestamp": timestamp,
                        "engagement": data_point.get("engagement_score", 0),
                    }
                )

        # Calculate averages and identify patterns
        hourly_avg = {
            hour: statistics.mean(scores)
            for hour, scores in patterns["hourly_activity"].items()
            if scores
        }
        daily_avg = {
            day: statistics.mean(scores)
            for day, scores in patterns["daily_activity"].items()
            if scores
        }

        # Find peak activity times
        peak_hours = sorted(hourly_avg.items(), key=lambda x: x[1], reverse=True)[:3]
        peak_days = sorted(daily_avg.items(), key=lambda x: x[1], reverse=True)[:2]

        return {
            "peak_hours": peak_hours,
            "peak_days": peak_days,
            "hourly_patterns": hourly_avg,
            "daily_patterns": daily_avg,
            "topic_trends": dict(patterns["topic_trends"]),
        }

    async def predict_optimal_posting_time(
        self, server_id: int, content_type: str = "general"
    ) -> Dict[str, Any]:
        """Predict optimal time to post content for maximum engagement"""
        patterns = self.activity_patterns.get(server_id, {})
        if not patterns:
            return {"error": "Insufficient data for prediction"}

        current_time = datetime.now(timezone.utc)

        # Calculate optimal times for next 48 hours
        optimal_times = []
        for hours_ahead in range(1, 49):
            future_time = current_time + timedelta(hours=hours_ahead)
            hour = future_time.hour
            day = future_time.weekday()

            # Base engagement score from historical patterns
            hour_score = patterns.get("hourly_patterns", {}).get(hour, 0.3)
            day_score = patterns.get("daily_patterns", {}).get(day, 0.3)

            # Combine scores with time decay
            engagement_prediction = (hour_score * 0.7 + day_score * 0.3) * (
                0.98**hours_ahead
            )

            optimal_times.append(
                {
                    "time": future_time,
                    "predicted_engagement": engagement_prediction,
                    "confidence": min(
                        0.9, len(patterns.get("hourly_patterns", {})) / 24 * 0.9
                    ),
                }
            )

        # Sort by predicted engagement
        optimal_times.sort(key=lambda x: x["predicted_engagement"], reverse=True)

        return {
            "top_times": optimal_times[:5],
            "next_optimal": optimal_times[0] if optimal_times else None,
            "content_type": content_type,
        }

    async def predict_mood_shift(
        self, server_id: int, current_mood: MoodSnapshot
    ) -> Optional[SocialPrediction]:
        """Predict potential mood shifts in the community"""
        # Analyze mood trajectory
        recent_moods = await self._get_recent_mood_history(server_id, hours=24)
        if len(recent_moods) < 5:
            return None

        # Calculate mood trend
        mood_values = [
            self._mood_to_numeric(mood.overall_mood) for mood in recent_moods
        ]
        trend = statistics.mean(mood_values[-3:]) - statistics.mean(mood_values[:3])

        # Detect rapid changes
        volatility = statistics.stdev(mood_values) if len(mood_values) > 1 else 0

        prediction_confidence = min(0.9, (len(recent_moods) / 24) * 0.8 + 0.1)

        if abs(trend) > 0.3 and volatility > 0.2:
            if trend > 0:
                predicted_mood = "improving"
                description = "Community mood appears to be improving based on recent interactions"
            else:
                predicted_mood = "declining"
                description = "Community mood may be declining - consider supportive interventions"

            return SocialPrediction(
                prediction_id=f"mood_{server_id}_{int(datetime.now().timestamp())}",
                server_id=server_id,
                prediction_type=SocialPredictionType.MOOD_SHIFT,
                confidence=prediction_confidence,
                predicted_time=datetime.now(timezone.utc) + timedelta(hours=2),
                description=description,
                contributing_factors=[
                    f"Mood trend: {trend:.2f}",
                    f"Volatility: {volatility:.2f}",
                    f"Recent interactions: {len(recent_moods)}",
                ],
                suggested_actions=[
                    "Monitor community interactions closely",
                    "Consider mood-boosting activities if declining",
                    "Celebrate positive moments if improving",
                ],
            )

        return None

    def _mood_to_numeric(self, mood: MoodState) -> float:
        """Convert mood state to numeric value for analysis"""
        mood_values = {
            MoodState.EUPHORIC: 1.0,
            MoodState.EXCITED: 0.7,
            MoodState.CONTENT: 0.5,
            MoodState.NEUTRAL: 0.0,
            MoodState.CONCERNED: -0.3,
            MoodState.FRUSTRATED: -0.6,
            MoodState.DEJECTED: -1.0,
        }
        return mood_values.get(mood, 0.0)

    async def _get_recent_mood_history(
        self, server_id: int, hours: int = 24
    ) -> List[MoodSnapshot]:
        """Get recent mood history for analysis"""
        # This would interface with the mood tracking system
        # For now, return empty list as placeholder
        return []


class CrossServerIntelligence:
    """Learns from broader ecosystem while maintaining privacy"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.pattern_database: Dict[str, Any] = {}
        self.privacy_filters: Set[str] = {
            "user_ids",
            "server_ids",
            "message_content",
            "personal_info",
        }

    async def extract_anonymized_patterns(
        self, server_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extract patterns while maintaining privacy"""
        anonymized = {}

        # Extract general communication patterns
        if "message_patterns" in server_data:
            patterns = server_data["message_patterns"]
            anonymized["communication_rhythms"] = {
                "avg_messages_per_hour": patterns.get("hourly_avg", 0),
                "peak_activity_distribution": patterns.get("hourly_distribution", {}),
                "response_time_patterns": patterns.get("response_times", []),
            }

        # Extract topic engagement patterns
        if "topic_engagement" in server_data:
            topics = server_data["topic_engagement"]
            anonymized["topic_patterns"] = {
                "popular_categories": list(topics.keys())[:10],  # No specific content
                "engagement_distribution": list(topics.values())[:10],
            }

        # Extract community health indicators
        if "wellness_metrics" in server_data:
            wellness = server_data["wellness_metrics"]
            anonymized["health_patterns"] = {
                "stress_indicators": wellness.get("avg_stress_level", 0),
                "social_connectivity": wellness.get("avg_connectivity", 0),
                "support_frequency": wellness.get("support_interactions", 0),
            }

        return anonymized

    async def learn_from_ecosystem(
        self, pattern_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Learn insights from anonymized cross-server patterns"""
        ecosystem_insights = {
            "optimal_community_sizes": [],
            "successful_engagement_patterns": {},
            "wellness_best_practices": {},
            "conflict_resolution_patterns": {},
        }

        # Analyze communication patterns across servers
        communication_data = [p.get("communication_rhythms", {}) for p in pattern_data]
        if communication_data:
            avg_hourly = [
                c.get("avg_messages_per_hour", 0)
                for c in communication_data
                if c.get("avg_messages_per_hour")
            ]
            if avg_hourly:
                ecosystem_insights["optimal_activity_range"] = {
                    "min": min(avg_hourly),
                    "max": max(avg_hourly),
                    "median": statistics.median(avg_hourly),
                }

        # Analyze wellness patterns
        wellness_data = [p.get("health_patterns", {}) for p in pattern_data]
        healthy_communities = [
            w for w in wellness_data if w.get("stress_indicators", 1) < 0.3
        ]

        if healthy_communities:
            ecosystem_insights["wellness_best_practices"] = {
                "avg_support_frequency": statistics.mean(
                    [h.get("support_frequency", 0) for h in healthy_communities]
                ),
                "avg_connectivity": statistics.mean(
                    [h.get("social_connectivity", 0) for h in healthy_communities]
                ),
            }

        return ecosystem_insights

    async def recommend_community_improvements(
        self, server_id: int, current_metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Recommend improvements based on ecosystem learning"""
        recommendations = []

        ecosystem_data = self.pattern_database.get("ecosystem_insights", {})

        # Check activity patterns
        current_activity = current_metrics.get("avg_hourly_messages", 0)
        optimal_range = ecosystem_data.get("optimal_activity_range", {})

        if optimal_range and current_activity < optimal_range.get("min", 0):
            recommendations.append(
                {
                    "type": "activity_boost",
                    "priority": "medium",
                    "description": "Community activity is below optimal range",
                    "suggestions": [
                        "Introduce daily discussion topics",
                        "Create interactive events",
                        "Encourage member introductions",
                    ],
                    "confidence": 0.7,
                }
            )

        # Check wellness indicators
        current_stress = current_metrics.get("avg_stress_level", 0.5)
        if current_stress > 0.6:
            wellness_practices = ecosystem_data.get("wellness_best_practices", {})
            recommendations.append(
                {
                    "type": "wellness_improvement",
                    "priority": "high",
                    "description": "Community stress levels are elevated",
                    "suggestions": [
                        "Increase supportive interactions",
                        "Create wellness check-in channels",
                        "Implement conflict resolution protocols",
                    ],
                    "confidence": 0.8,
                    "benchmark": wellness_practices,
                }
            )

        return recommendations


class WellnessCompanion:
    """Genuine care system for community health monitoring"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.user_profiles: Dict[Tuple[int, int], WellnessProfile] = (
            {}
        )  # (server_id, user_id) -> profile
        self.intervention_cooldowns: Dict[Tuple[int, int], datetime] = {}

    async def monitor_user_wellness(
        self, user_id: int, server_id: int, message_data: Dict[str, Any]
    ) -> Optional[WellnessAlert]:
        """Monitor individual user wellness based on communication patterns"""
        profile = await self._get_wellness_profile(user_id, server_id)

        # Analyze message sentiment
        sentiment = await self._analyze_message_sentiment(
            message_data.get("content", "")
        )
        profile.message_sentiment_trend.append(sentiment)

        # Keep only recent data
        if len(profile.message_sentiment_trend) > 50:
            profile.message_sentiment_trend = profile.message_sentiment_trend[-50:]

        # Detect concerning patterns
        if len(profile.message_sentiment_trend) >= 10:
            recent_sentiment = statistics.mean(profile.message_sentiment_trend[-10:])
            overall_sentiment = statistics.mean(profile.message_sentiment_trend)

            # Check for declining sentiment
            if recent_sentiment < -0.3 and recent_sentiment < overall_sentiment - 0.2:
                profile.stress_level = min(1.0, profile.stress_level + 0.1)

                if profile.stress_level > 0.7:
                    return WellnessAlert.STRESS_DETECTED

        # Monitor activity patterns
        current_time = datetime.now(timezone.utc)
        last_activity = message_data.get("timestamp", current_time)

        # Check for isolation risk
        if hasattr(profile, "last_interaction_with_others"):
            hours_since_social = (
                current_time - profile.last_interaction_with_others
            ).total_seconds() / 3600
            if hours_since_social > 72:  # 3 days without social interaction
                profile.isolation_risk = min(1.0, profile.isolation_risk + 0.1)

                if profile.isolation_risk > 0.6:
                    return WellnessAlert.ISOLATION_RISK

        await self._save_wellness_profile(profile)
        return None

    async def suggest_intervention(
        self, user_id: int, server_id: int, alert_type: WellnessAlert
    ) -> Dict[str, Any]:
        """Suggest appropriate intervention based on wellness alert"""
        profile = await self._get_wellness_profile(user_id, server_id)

        # Check intervention cooldown
        cooldown_key = (server_id, user_id)
        if cooldown_key in self.intervention_cooldowns:
            if datetime.now(timezone.utc) < self.intervention_cooldowns[cooldown_key]:
                return {"intervention": "cooldown_active"}

        interventions = {
            WellnessAlert.STRESS_DETECTED: {
                "type": "gentle_check_in",
                "message": "I've noticed you might be going through a tough time. Want to talk about it? ðŸ’™",
                "actions": ["offer_resources", "suggest_break", "connect_with_support"],
                "follow_up_hours": 24,
            },
            WellnessAlert.ISOLATION_RISK: {
                "type": "social_connection",
                "message": "Hey! We haven't chatted in a while. How are you doing? The community misses you! ðŸŒŸ",
                "actions": [
                    "invite_to_activity",
                    "introduce_to_others",
                    "share_community_updates",
                ],
                "follow_up_hours": 48,
            },
            WellnessAlert.BURNOUT_SIGNS: {
                "type": "wellness_support",
                "message": "You've been really active lately! Remember to take breaks and take care of yourself. ðŸŒ±",
                "actions": [
                    "suggest_self_care",
                    "reduce_responsibilities",
                    "offer_help",
                ],
                "follow_up_hours": 72,
            },
        }

        intervention = interventions.get(alert_type, {})
        if intervention:
            # Set cooldown to prevent overwhelming the user
            cooldown_hours = intervention.get("follow_up_hours", 24)
            self.intervention_cooldowns[cooldown_key] = datetime.now(
                timezone.utc
            ) + timedelta(hours=cooldown_hours)

            # Log intervention
            profile.recent_interventions.append(
                {
                    "type": alert_type.value,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "intervention": intervention["type"],
                }
            )

            await self._save_wellness_profile(profile)

        return intervention

    async def _analyze_message_sentiment(self, message: str) -> float:
        """Analyze sentiment of a message (-1.0 to 1.0)"""
        # Simplified sentiment analysis
        positive_words = [
            "happy",
            "good",
            "great",
            "awesome",
            "love",
            "excited",
            "wonderful",
            "amazing",
            "fantastic",
        ]
        negative_words = [
            "sad",
            "bad",
            "terrible",
            "hate",
            "awful",
            "horrible",
            "depressed",
            "frustrated",
            "angry",
        ]

        message_lower = message.lower()
        positive_count = sum(1 for word in positive_words if word in message_lower)
        negative_count = sum(1 for word in negative_words if word in message_lower)

        if positive_count + negative_count == 0:
            return 0.0

        sentiment = (positive_count - negative_count) / (
            positive_count + negative_count
        )
        return max(-1.0, min(1.0, sentiment))

    async def _get_wellness_profile(
        self, user_id: int, server_id: int
    ) -> WellnessProfile:
        """Get or create wellness profile for user"""
        key = (server_id, user_id)
        if key not in self.user_profiles:
            self.user_profiles[key] = WellnessProfile(
                user_id=user_id, server_id=server_id
            )
        return self.user_profiles[key]

    async def _save_wellness_profile(self, profile: WellnessProfile):
        """Save wellness profile to database"""
        # Implementation would save to database
        pass


class MemoryPalace:
    """Advanced memory architecture for complex community memories"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.memory_fragments: Dict[str, MemoryFragment] = {}
        self.memory_connections: Dict[str, List[str]] = defaultdict(list)
        self.importance_weights = {
            "frequency": 0.3,  # How often it's referenced
            "emotional_weight": 0.4,  # Emotional significance
            "recency": 0.2,  # How recent it is
            "uniqueness": 0.1,  # How unique/rare it is
        }

    async def store_memory(
        self,
        server_id: int,
        memory_type: str,
        content: Dict[str, Any],
        participants: List[int],
        emotional_weight: float = 0.0,
    ) -> str:
        """Store a new memory fragment"""
        memory_id = f"{server_id}_{memory_type}_{int(datetime.now().timestamp())}"

        memory = MemoryFragment(
            memory_id=memory_id,
            server_id=server_id,
            memory_type=memory_type,
            content=content,
            emotional_weight=emotional_weight,
            importance_score=0.5,  # Initial score
            participants=participants,
            tags=await self._extract_tags(content),
            created_at=datetime.now(timezone.utc),
            last_accessed=datetime.now(timezone.utc),
        )

        # Calculate importance score
        memory.importance_score = await self._calculate_importance(memory)

        # Find connections to existing memories
        connections = await self._find_memory_connections(memory)
        memory.connections = connections

        # Update connection graph
        for connected_id in connections:
            self.memory_connections[connected_id].append(memory_id)
            self.memory_connections[memory_id].append(connected_id)

        self.memory_fragments[memory_id] = memory
        await self._save_memory(memory)

        return memory_id

    async def recall_memories(
        self, server_id: int, context: Dict[str, Any], limit: int = 5
    ) -> List[MemoryFragment]:
        """Recall relevant memories based on context"""
        server_memories = [
            m for m in self.memory_fragments.values() if m.server_id == server_id
        ]

        if not server_memories:
            return []

        # Score memories based on relevance to current context
        scored_memories = []
        for memory in server_memories:
            relevance_score = await self._calculate_relevance(memory, context)
            memory.access_count += 1
            memory.last_accessed = datetime.now(timezone.utc)

            scored_memories.append((memory, relevance_score))

        # Sort by relevance and importance
        scored_memories.sort(key=lambda x: x[1] * x[0].importance_score, reverse=True)

        return [memory for memory, score in scored_memories[:limit]]

    async def _extract_tags(self, content: Dict[str, Any]) -> List[str]:
        """Extract relevant tags from memory content"""
        tags = []

        # Extract from content keys and values
        for key, value in content.items():
            tags.append(key)
            if isinstance(value, str) and len(value) < 30:
                tags.extend(value.lower().split())

        # Remove common words and duplicates
        common_words = {
            "the",
            "and",
            "or",
            "but",
            "in",
            "on",
            "at",
            "to",
            "for",
            "of",
            "with",
            "by",
            "is",
            "are",
            "was",
            "were",
        }
        tags = list(
            set(
                [
                    tag
                    for tag in tags
                    if tag.lower() not in common_words and len(tag) > 2
                ]
            )
        )

        return tags[:10]  # Limit to 10 tags

    async def _calculate_importance(self, memory: MemoryFragment) -> float:
        """Calculate importance score for a memory"""
        score = 0.0

        # Emotional weight contribution
        score += (
            abs(memory.emotional_weight) * self.importance_weights["emotional_weight"]
        )

        # Participant count (more participants = more important)
        participant_score = min(1.0, len(memory.participants) / 10)
        score += participant_score * 0.2

        # Content richness
        content_score = min(1.0, len(str(memory.content)) / 500)
        score += content_score * 0.1

        return min(1.0, score)

    async def _find_memory_connections(self, memory: MemoryFragment) -> List[str]:
        """Find connections between memories"""
        connections = []

        for existing_id, existing_memory in self.memory_fragments.items():
            if existing_memory.server_id != memory.server_id:
                continue

            # Check for participant overlap
            participant_overlap = set(memory.participants) & set(
                existing_memory.participants
            )
            if len(participant_overlap) >= 2:
                connections.append(existing_id)
                continue

            # Check for tag overlap
            tag_overlap = set(memory.tags) & set(existing_memory.tags)
            if len(tag_overlap) >= 2:
                connections.append(existing_id)
                continue

            # Check for temporal proximity (within 24 hours)
            time_diff = abs(
                (memory.created_at - existing_memory.created_at).total_seconds()
            )
            if time_diff < 86400:  # 24 hours
                connections.append(existing_id)

        return connections[:5]  # Limit connections

    async def _calculate_relevance(
        self, memory: MemoryFragment, context: Dict[str, Any]
    ) -> float:
        """Calculate relevance of memory to current context"""
        relevance = 0.0

        # Check participant relevance
        if "participants" in context:
            context_participants = set(context["participants"])
            memory_participants = set(memory.participants)
            overlap = len(context_participants & memory_participants)
            if overlap > 0:
                relevance += 0.4 * (overlap / len(memory_participants))

        # Check topic/tag relevance
        if "topics" in context:
            context_topics = set(context["topics"])
            memory_tags = set(memory.tags)
            overlap = len(context_topics & memory_tags)
            if overlap > 0:
                relevance += 0.3 * (overlap / len(memory_tags))

        # Recency bonus
        days_old = (datetime.now(timezone.utc) - memory.created_at).days
        recency_score = max(0, 1 - (days_old / 30))  # Decay over 30 days
        relevance += 0.2 * recency_score

        # Access frequency bonus
        access_score = min(1.0, memory.access_count / 10)
        relevance += 0.1 * access_score

        return min(1.0, relevance)

    async def _save_memory(self, memory: MemoryFragment):
        """Save memory to database"""
        # Implementation would save to database
        pass


class MoodContagionSystem:
    """Tracks and models emotional atmosphere and mood spread"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.mood_history: Dict[int, List[MoodSnapshot]] = defaultdict(list)
        self.contagion_models: Dict[int, Dict[str, Any]] = {}

    async def track_mood_shift(
        self, server_id: int, user_id: int, message_data: Dict[str, Any]
    ) -> MoodSnapshot:
        """Track how a user's message affects overall community mood"""
        current_mood = await self._calculate_current_mood(server_id)

        # Analyze message emotional impact
        message_sentiment = await self._analyze_message_sentiment(
            message_data.get("content", "")
        )
        message_energy = await self._analyze_message_energy(
            message_data.get("content", "")
        )

        # Calculate user's influence factor
        user_influence = await self._get_user_influence(server_id, user_id)

        # Model mood contagion
        mood_delta = message_sentiment * user_influence * 0.1
        new_mood_value = self._mood_to_numeric(current_mood.overall_mood) + mood_delta
        new_mood_state = self._numeric_to_mood(new_mood_value)

        # Create new mood snapshot
        new_snapshot = MoodSnapshot(
            server_id=server_id,
            timestamp=datetime.now(timezone.utc),
            overall_mood=new_mood_state,
            mood_intensity=abs(new_mood_value),
            dominant_emotions=await self._analyze_dominant_emotions(message_data),
            active_users=current_mood.active_users,
            message_sentiment_avg=message_sentiment,
            topics_discussed=message_data.get("topics", []),
            mood_influencers=[user_id],
            external_factors=[],
        )

        # Update mood history
        self.mood_history[server_id].append(new_snapshot)
        if len(self.mood_history[server_id]) > 100:
            self.mood_history[server_id] = self.mood_history[server_id][-100:]

        # Update contagion model
        await self._update_contagion_model(server_id, user_id, mood_delta)

        return new_snapshot

    async def predict_mood_spread(
        self, server_id: int, initial_user_id: int, emotional_event: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Predict how an emotional event will spread through the community"""
        contagion_model = self.contagion_models.get(server_id, {})

        # Get social graph
        social_connections = await self._get_social_connections(server_id)

        # Simulate mood spread
        affected_users = {initial_user_id: 1.0}  # user_id -> influence_received
        spread_waves = []

        for wave in range(5):  # Model 5 waves of spread
            new_affected = {}

            for affected_user, current_influence in affected_users.items():
                if current_influence < 0.1:  # Too weak to spread further
                    continue

                # Find connected users
                connections = social_connections.get(affected_user, [])
                for connected_user, connection_strength in connections:
                    if connected_user not in affected_users:
                        # Calculate transmitted influence
                        transmission_rate = contagion_model.get(
                            "transmission_rate", 0.3
                        )
                        transmitted_influence = (
                            current_influence * connection_strength * transmission_rate
                        )

                        if transmitted_influence > 0.05:  # Minimum threshold
                            new_affected[connected_user] = transmitted_influence

            if new_affected:
                affected_users.update(new_affected)
                spread_waves.append(
                    {
                        "wave": wave + 1,
                        "newly_affected": list(new_affected.keys()),
                        "influence_levels": dict(new_affected),
                    }
                )
            else:
                break

        return {
            "total_affected_users": len(affected_users),
            "spread_waves": spread_waves,
            "predicted_duration_hours": len(spread_waves) * 2,  # Rough estimate
            "peak_influence_time": f"{len(spread_waves)} hours",
        }

    async def _calculate_current_mood(self, server_id: int) -> MoodSnapshot:
        """Calculate current community mood"""
        recent_snapshots = (
            self.mood_history[server_id][-10:] if self.mood_history[server_id] else []
        )

        if not recent_snapshots:
            # Default neutral mood
            return MoodSnapshot(
                server_id=server_id,
                timestamp=datetime.now(timezone.utc),
                overall_mood=MoodState.NEUTRAL,
                mood_intensity=0.0,
                dominant_emotions={},
                active_users=0,
                message_sentiment_avg=0.0,
                topics_discussed=[],
                mood_influencers=[],
                external_factors=[],
            )

        # Average recent moods
        avg_mood_value = statistics.mean(
            [self._mood_to_numeric(snap.overall_mood) for snap in recent_snapshots]
        )
        avg_intensity = statistics.mean(
            [snap.mood_intensity for snap in recent_snapshots]
        )

        return MoodSnapshot(
            server_id=server_id,
            timestamp=datetime.now(timezone.utc),
            overall_mood=self._numeric_to_mood(avg_mood_value),
            mood_intensity=avg_intensity,
            dominant_emotions={},
            active_users=len(
                set(sum([snap.mood_influencers for snap in recent_snapshots], []))
            ),
            message_sentiment_avg=statistics.mean(
                [snap.message_sentiment_avg for snap in recent_snapshots]
            ),
            topics_discussed=[],
            mood_influencers=[],
            external_factors=[],
        )

    def _mood_to_numeric(self, mood: MoodState) -> float:
        """Convert mood to numeric value"""
        mood_values = {
            MoodState.EUPHORIC: 1.0,
            MoodState.EXCITED: 0.7,
            MoodState.CONTENT: 0.5,
            MoodState.NEUTRAL: 0.0,
            MoodState.CONCERNED: -0.3,
            MoodState.FRUSTRATED: -0.6,
            MoodState.DEJECTED: -1.0,
        }
        return mood_values.get(mood, 0.0)

    def _numeric_to_mood(self, value: float) -> MoodState:
        """Convert numeric value to mood state"""
        if value >= 0.8:
            return MoodState.EUPHORIC
        elif value >= 0.5:
            return MoodState.EXCITED
        elif value >= 0.2:
            return MoodState.CONTENT
        elif value >= -0.2:
            return MoodState.NEUTRAL
        elif value >= -0.5:
            return MoodState.CONCERNED
        elif value >= -0.8:
            return MoodState.FRUSTRATED
        else:
            return MoodState.DEJECTED

    async def _analyze_message_sentiment(self, message: str) -> float:
        """Analyze message sentiment"""
        # Reuse the sentiment analysis from WellnessCompanion
        positive_words = [
            "happy",
            "good",
            "great",
            "awesome",
            "love",
            "excited",
            "wonderful",
            "amazing",
            "fantastic",
        ]
        negative_words = [
            "sad",
            "bad",
            "terrible",
            "hate",
            "awful",
            "horrible",
            "depressed",
            "frustrated",
            "angry",
        ]

        message_lower = message.lower()
        positive_count = sum(1 for word in positive_words if word in message_lower)
        negative_count = sum(1 for word in negative_words if word in message_lower)

        if positive_count + negative_count == 0:
            return 0.0

        sentiment = (positive_count - negative_count) / (
            positive_count + negative_count
        )
        return max(-1.0, min(1.0, sentiment))

    async def _analyze_message_energy(self, message: str) -> float:
        """Analyze message energy level"""
        high_energy_indicators = [
            "!!!",
            "!",
            "wow",
            "amazing",
            "incredible",
            "ðŸŽ‰",
            "ðŸš€",
            "âš¡",
        ]
        low_energy_indicators = ["...", "meh", "tired", "exhausted", "ðŸ˜´", "ðŸ˜‘"]

        message_lower = message.lower()
        high_count = sum(
            1 for indicator in high_energy_indicators if indicator in message_lower
        )
        low_count = sum(
            1 for indicator in low_energy_indicators if indicator in message_lower
        )

        # Count exclamation marks
        exclamation_count = message.count("!")
        high_count += min(3, exclamation_count)  # Cap at 3

        if high_count + low_count == 0:
            return 0.5  # Neutral energy

        energy = high_count / (high_count + low_count)
        return max(0.0, min(1.0, energy))

    async def _get_user_influence(self, server_id: int, user_id: int) -> float:
        """Calculate user's influence on community mood"""
        # Simplified influence calculation
        # In a full implementation, this would consider:
        # - User's role/permissions
        # - How often their messages get reactions
        # - How long they've been in the server
        # - Their historical mood impact
        return 0.5  # Default moderate influence

    async def _analyze_dominant_emotions(
        self, message_data: Dict[str, Any]
    ) -> Dict[str, float]:
        """Analyze dominant emotions in a message"""
        emotions = {
            "joy": 0.0,
            "anger": 0.0,
            "sadness": 0.0,
            "fear": 0.0,
            "surprise": 0.0,
            "disgust": 0.0,
        }

        message = message_data.get("content", "").lower()

        # Simple emotion detection based on keywords
        emotion_keywords = {
            "joy": ["happy", "excited", "love", "awesome", "great", "ðŸ˜€", "ðŸ˜Š", "ðŸŽ‰"],
            "anger": ["angry", "frustrated", "mad", "hate", "stupid", "ðŸ˜ ", "ðŸ˜¡"],
            "sadness": ["sad", "depressed", "cry", "upset", "disappointed", "ðŸ˜¢", "ðŸ˜­"],
            "fear": ["scared", "afraid", "worried", "anxious", "nervous", "ðŸ˜¨", "ðŸ˜°"],
            "surprise": [
                "wow",
                "amazing",
                "incredible",
                "unexpected",
                "shocked",
                "ðŸ˜²",
                "ðŸ˜®",
            ],
            "disgust": ["gross", "disgusting", "yuck", "eww", "terrible", "ðŸ¤¢", "ðŸ¤®"],
        }

        for emotion, keywords in emotion_keywords.items():
            count = sum(1 for keyword in keywords if keyword in message)
            emotions[emotion] = min(1.0, count * 0.3)

        return emotions

    async def _update_contagion_model(
        self, server_id: int, user_id: int, mood_delta: float
    ):
        """Update mood contagion model for the server"""
        if server_id not in self.contagion_models:
            self.contagion_models[server_id] = {
                "transmission_rate": 0.3,
                "decay_rate": 0.1,
                "amplification_factors": {},
                "user_influence_history": defaultdict(list),
            }

        model = self.contagion_models[server_id]
        model["user_influence_history"][user_id].append(abs(mood_delta))

        # Keep only recent history
        if len(model["user_influence_history"][user_id]) > 20:
            model["user_influence_history"][user_id] = model["user_influence_history"][
                user_id
            ][-20:]

    async def _get_social_connections(
        self, server_id: int
    ) -> Dict[int, List[Tuple[int, float]]]:
        """Get social connection graph for the server"""
        # Simplified social graph
        # In a full implementation, this would analyze:
        # - Who responds to whom
        # - Who mentions whom
        # - Reaction patterns
        # - Temporal interaction patterns
        return {}


class CommunitySage:
    """Wise advisor mode with deep community insights"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.wisdom_database: Dict[str, Any] = {}
        self.community_insights: Dict[int, Dict[str, Any]] = {}

    async def analyze_community_health(self, server_id: int) -> Dict[str, Any]:
        """Provide deep analysis of community health and dynamics"""
        insights = {
            "overall_health_score": 0.0,
            "strengths": [],
            "areas_for_growth": [],
            "social_dynamics": {},
            "wellness_indicators": {},
            "growth_opportunities": [],
            "wisdom_insights": [],
        }

        # Gather data from all systems
        # This would integrate with all other systems to provide comprehensive analysis

        # Placeholder comprehensive analysis
        insights["overall_health_score"] = 0.75
        insights["strengths"] = [
            "Active participation from core members",
            "Supportive community atmosphere",
            "Good balance of serious and lighthearted content",
        ]
        insights["areas_for_growth"] = [
            "Could benefit from more new member integration activities",
            "Some members show signs of social isolation",
            "Peak activity times could be better utilized",
        ]

        return insights

    async def provide_sage_advice(
        self, server_id: int, situation: str, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Provide wise, contextual advice for community situations"""
        advice = {
            "primary_guidance": "",
            "detailed_recommendations": [],
            "philosophical_insight": "",
            "practical_steps": [],
            "long_term_vision": "",
            "wisdom_level": "sage",
        }

        situation_lower = situation.lower()

        if "conflict" in situation_lower or "argument" in situation_lower:
            advice["primary_guidance"] = (
                "Conflicts are opportunities for deeper understanding and stronger bonds."
            )
            advice["detailed_recommendations"] = [
                "Create space for all voices to be heard without judgment",
                "Focus on underlying needs rather than surface positions",
                "Facilitate a cooling-off period if emotions are high",
                "Help parties find common ground and shared values",
            ]
            advice["philosophical_insight"] = (
                "The strongest communities are forged not in the absence of conflict, but in how they navigate through it with grace and wisdom."
            )

        elif "growth" in situation_lower or "expand" in situation_lower:
            advice["primary_guidance"] = (
                "True growth comes from nurturing depth alongside breadth."
            )
            advice["detailed_recommendations"] = [
                "Focus on quality connections rather than just numbers",
                "Create meaningful onboarding experiences for new members",
                "Develop mentorship relationships between experienced and new members",
                "Establish clear community values and culture transmission",
            ]
            advice["philosophical_insight"] = (
                "A community that grows without losing its soul is one that knows its values and lives them daily."
            )

        elif "wellness" in situation_lower or "mental health" in situation_lower:
            advice["primary_guidance"] = (
                "A community's strength is measured by how it cares for its most vulnerable members."
            )
            advice["detailed_recommendations"] = [
                "Create safe spaces for members to share struggles",
                "Train trusted members in basic mental health support",
                "Establish clear pathways to professional resources",
                "Normalize conversations about mental health and self-care",
            ]
            advice["philosophical_insight"] = (
                "When we hold space for each other's humanity - the struggles as well as the triumphs - we create something sacred."
            )

        # Add practical steps based on community context
        if context.get("community_size", 0) < 50:
            advice["practical_steps"].append(
                "Leverage intimate community size for deep, personal connections"
            )
        elif context.get("community_size", 0) > 500:
            advice["practical_steps"].append(
                "Create smaller sub-groups to maintain personal connection at scale"
            )

        advice["long_term_vision"] = (
            "A thriving community where every member feels valued, heard, and empowered to contribute their unique gifts to the collective journey."
        )

        return advice

    async def generate_community_wisdom(
        self, server_id: int, historical_data: List[Dict[str, Any]]
    ) -> List[str]:
        """Generate wisdom insights based on community history"""
        wisdom_insights = []

        if len(historical_data) > 100:  # Sufficient data for deep insights
            # Analyze patterns over time
            monthly_activity = self._group_by_month(historical_data)

            # Look for seasonal patterns
            if len(monthly_activity) >= 6:
                peak_months = sorted(
                    monthly_activity.items(), key=lambda x: x[1], reverse=True
                )[:2]
                wisdom_insights.append(
                    f"Your community shows natural rhythms, with peak energy in {peak_months[0][0]} and {peak_months[1][0]}. "
                    f"Honor these cycles - plan major initiatives during peak times and allow for rest during quieter periods."
                )

            # Analyze growth patterns
            early_data = historical_data[: len(historical_data) // 3]
            recent_data = historical_data[-len(historical_data) // 3 :]

            early_sentiment = statistics.mean(
                [d.get("sentiment", 0) for d in early_data]
            )
            recent_sentiment = statistics.mean(
                [d.get("sentiment", 0) for d in recent_data]
            )

            if recent_sentiment > early_sentiment + 0.2:
                wisdom_insights.append(
                    "Your community has grown not just in size, but in joy and positivity. "
                    "This suggests strong leadership and a culture that truly serves its members. "
                    "Document what's working so you can preserve and replicate these elements."
                )

            # Look for resilience patterns
            stress_events = [
                d for d in historical_data if d.get("stress_level", 0) > 0.7
            ]
            if stress_events:
                recovery_times = []
                for event in stress_events:
                    # Find how long it took to recover (simplified)
                    event_time = datetime.fromisoformat(event["timestamp"])
                    later_data = [
                        d
                        for d in historical_data
                        if datetime.fromisoformat(d["timestamp"]) > event_time
                        and datetime.fromisoformat(d["timestamp"])
                        < event_time + timedelta(days=7)
                    ]

                    if (
                        later_data
                        and statistics.mean(
                            [d.get("stress_level", 0) for d in later_data]
                        )
                        < 0.3
                    ):
                        recovery_times.append(True)

                if len(recovery_times) >= len(stress_events) * 0.8:
                    wisdom_insights.append(
                        "Your community has demonstrated remarkable resilience. "
                        "When challenges arise, you consistently support each other and bounce back stronger. "
                        "This is a rare and precious quality - celebrate and protect this collective strength."
                    )

        # Add universal wisdom
        wisdom_insights.extend(
            [
                "Every member who joins your community is seeking connection and belonging. "
                "Your role is not to change them, but to create space where they can flourish as themselves.",
                "The most powerful communities are built on small, consistent acts of kindness "
                "rather than grand gestures. Pay attention to the quiet moments of support.",
                "Growth without intention leads to dilution. Know your values, live them daily, "
                "and let them guide every decision about your community's evolution.",
            ]
        )

        return wisdom_insights[:5]  # Return top 5 insights

    def _group_by_month(self, data: List[Dict[str, Any]]) -> Dict[str, float]:
        """Group data by month for pattern analysis"""
        monthly_data = defaultdict(list)

        for item in data:
            try:
                timestamp = datetime.fromisoformat(item["timestamp"])
                month_key = f"{timestamp.strftime('%B')} {timestamp.year}"
                monthly_data[month_key].append(item.get("activity_score", 1))
            except:
                continue

        return {
            month: statistics.mean(scores) for month, scores in monthly_data.items()
        }


class AdvancedIntelligenceEngine:
    """Main orchestrator for all advanced intelligence features"""

    def __init__(self):
        self.logger = logger
        self.db_path = Path("data/advanced_intelligence.db")
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        # Initialize all subsystems
        self.social_predictor = TimeAwareSocialPredictor(self.db_path)
        self.cross_server_intelligence = CrossServerIntelligence(self.db_path)
        self.wellness_companion = WellnessCompanion(self.db_path)
        self.memory_palace = MemoryPalace(self.db_path)
        self.mood_contagion = MoodContagionSystem(self.db_path)
        self.community_sage = CommunitySage(self.db_path)

        self._setup_database()
        logger.info("Advanced Intelligence Engine initialized")

    def _setup_database(self):
        """Setup comprehensive database for advanced intelligence"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Social predictions table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS social_predictions (
                        id TEXT PRIMARY KEY,
                        server_id INTEGER,
                        prediction_type TEXT,
                        confidence REAL,
                        predicted_time TIMESTAMP,
                        description TEXT,
                        contributing_factors TEXT,
                        suggested_actions TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        validated INTEGER,
                        actual_outcome TEXT
                    )
                """
                )

                # Wellness profiles table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS wellness_profiles (
                        server_id INTEGER,
                        user_id INTEGER,
                        profile_data TEXT,
                        stress_level REAL,
                        isolation_risk REAL,
                        last_update TIMESTAMP,
                        PRIMARY KEY (server_id, user_id)
                    )
                """
                )

                # Memory fragments table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS memory_fragments (
                        memory_id TEXT PRIMARY KEY,
                        server_id INTEGER,
                        memory_type TEXT,
                        content TEXT,
                        emotional_weight REAL,
                        importance_score REAL,
                        participants TEXT,
                        tags TEXT,
                        created_at TIMESTAMP,
                        last_accessed TIMESTAMP,
                        access_count INTEGER DEFAULT 0,
                        connections TEXT
                    )
                """
                )

                # Mood snapshots table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS mood_snapshots (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        server_id INTEGER,
                        timestamp TIMESTAMP,
                        overall_mood TEXT,
                        mood_intensity REAL,
                        dominant_emotions TEXT,
                        active_users INTEGER,
                        message_sentiment_avg REAL,
                        topics_discussed TEXT,
                        mood_influencers TEXT,
                        external_factors TEXT
                    )
                """
                )

                # Community insights table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS community_insights (
                        server_id INTEGER PRIMARY KEY,
                        insights_data TEXT,
                        health_score REAL,
                        last_analysis TIMESTAMP,
                        wisdom_insights TEXT
                    )
                """
                )

                # Cross-server patterns table
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS cross_server_patterns (
                        pattern_id TEXT PRIMARY KEY,
                        pattern_type TEXT,
                        anonymized_data TEXT,
                        ecosystem_insights TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """
                )

                # Create indexes for performance
                conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_predictions_server_time ON social_predictions (server_id, predicted_time)"
                )
                conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_wellness_server_user ON wellness_profiles (server_id, user_id)"
                )
                conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_memories_server_type ON memory_fragments (server_id, memory_type)"
                )
                conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_mood_server_time ON mood_snapshots (server_id, timestamp)"
                )

                conn.commit()
                logger.info("Advanced intelligence database initialized")

        except Exception as e:
            logger.error(f"Database setup error: {e}")

    async def process_community_event(
        self, server_id: int, event_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Process a community event through all intelligence systems"""
        results = {
            "predictions": [],
            "wellness_alerts": [],
            "memory_updates": [],
            "mood_changes": {},
            "sage_insights": [],
        }

        try:
            # Update mood tracking
            if "message_data" in event_data:
                mood_snapshot = await self.mood_contagion.track_mood_shift(
                    server_id, event_data.get("user_id"), event_data["message_data"]
                )
                results["mood_changes"] = {
                    "new_mood": mood_snapshot.overall_mood.value,
                    "intensity": mood_snapshot.mood_intensity,
                }

            # Check for wellness concerns
            if "user_id" in event_data:
                wellness_alert = await self.wellness_companion.monitor_user_wellness(
                    event_data["user_id"], server_id, event_data.get("message_data", {})
                )
                if wellness_alert:
                    intervention = await self.wellness_companion.suggest_intervention(
                        event_data["user_id"], server_id, wellness_alert
                    )
                    results["wellness_alerts"].append(
                        {
                            "alert_type": wellness_alert.value,
                            "intervention": intervention,
                        }
                    )

            # Store significant events in memory palace
            if event_data.get("significance_score", 0) > 0.5:
                memory_id = await self.memory_palace.store_memory(
                    server_id=server_id,
                    memory_type=event_data.get("event_type", "general"),
                    content=event_data,
                    participants=event_data.get("participants", []),
                    emotional_weight=event_data.get("emotional_weight", 0.0),
                )
                results["memory_updates"].append(memory_id)

            # Generate predictions
            if event_data.get("trigger_predictions", True):
                # Predict mood shifts
                current_mood = await self.mood_contagion._calculate_current_mood(
                    server_id
                )
                mood_prediction = await self.social_predictor.predict_mood_shift(
                    server_id, current_mood
                )
                if mood_prediction:
                    results["predictions"].append(mood_prediction)

                # Predict optimal posting times
                optimal_times = (
                    await self.social_predictor.predict_optimal_posting_time(server_id)
                )
                results["predictions"].append(
                    {"type": "optimal_posting", "data": optimal_times}
                )

        except Exception as e:
            logger.error(f"Error processing community event: {e}")
            results["error"] = str(e)

        return results

    async def get_comprehensive_insights(self, server_id: int) -> Dict[str, Any]:
        """Get comprehensive insights about a community"""
        insights = {
            "community_health": {},
            "predictive_insights": {},
            "wellness_overview": {},
            "memory_highlights": [],
            "mood_analysis": {},
            "sage_wisdom": [],
        }

        try:
            # Community health analysis
            insights["community_health"] = (
                await self.community_sage.analyze_community_health(server_id)
            )

            # Get recent predictions
            # This would query the database for recent predictions

            # Wellness overview
            # This would aggregate wellness data

            # Memory highlights
            memory_context = {"topics": ["general"], "participants": []}
            insights["memory_highlights"] = await self.memory_palace.recall_memories(
                server_id, memory_context, limit=3
            )

            # Mood analysis
            current_mood = await self.mood_contagion._calculate_current_mood(server_id)
            insights["mood_analysis"] = {
                "current_mood": current_mood.overall_mood.value,
                "intensity": current_mood.mood_intensity,
                "recent_trend": "stable",  # Would calculate from history
            }

            # Sage wisdom
            insights["sage_wisdom"] = (
                await self.community_sage.generate_community_wisdom(server_id, [])
            )

        except Exception as e:
            logger.error(f"Error getting comprehensive insights: {e}")
            insights["error"] = str(e)

        return insights


# Global advanced intelligence engine instance
_advanced_intelligence_engine: Optional[AdvancedIntelligenceEngine] = None


def get_advanced_intelligence_engine() -> Optional[AdvancedIntelligenceEngine]:
    """Get the global advanced intelligence engine instance"""
    return _advanced_intelligence_engine


def initialize_advanced_intelligence_engine() -> AdvancedIntelligenceEngine:
    """Initialize the global advanced intelligence engine"""
    global _advanced_intelligence_engine
    _advanced_intelligence_engine = AdvancedIntelligenceEngine()
    return _advanced_intelligence_engine
